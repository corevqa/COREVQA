# -*- coding: utf-8 -*-
"""Example Evaluation Pipeline with COREVQA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YJaYwfqV9l_byIPIdLTSmX81g-Zo82eF
"""

!pip install -q huggingface_hub
!pip install -q openai

from PIL import Image
import requests
from io import BytesIO
import matplotlib.pyplot as plt
import pandas as pd
import os
import zipfile
from huggingface_hub import hf_hub_download
import pandas as pd
import openai
import base64

# Load COREVQA from Huggingfaces
CSV_PATH = hf_hub_download(repo_id="COREVQA2025/COREVQA", filename="COREVQA.csv", repo_type="dataset")

UNZIP_DIR_TRAIN01 = "/content/crowdhuman_train01"
UNZIP_DIR_TRAIN02 = "/content/crowdhuman_train02"
IMAGE_FOLDER_TRAIN01 = os.path.join(UNZIP_DIR_TRAIN01, "Images")
IMAGE_FOLDER_TRAIN02 = os.path.join(UNZIP_DIR_TRAIN02, "Images")

try:
    zip_path_01 = hf_hub_download(repo_id="COREVQA2025/COREVQA", filename="CrowdHuman_train01.zip", repo_type="dataset")
    os.makedirs(UNZIP_DIR_TRAIN01, exist_ok=True)
    with zipfile.ZipFile(zip_path_01, 'r') as zip_ref:
        zip_ref.extractall(UNZIP_DIR_TRAIN01)
except:
    pass

try:
    zip_path_02 = hf_hub_download(repo_id="COREVQA2025/COREVQA", filename="CrowdHuman_train02.zip", repo_type="dataset")
    os.makedirs(UNZIP_DIR_TRAIN02, exist_ok=True)
    with zipfile.ZipFile(zip_path_02, 'r') as zip_ref:
        zip_ref.extractall(UNZIP_DIR_TRAIN02)
except:
    pass

df = pd.read_csv(CSV_PATH, encoding="utf-8-sig")

#Copy and paste your gpt api key in the string below
openai.api_key = "YOUR_API_KEY_HERE"

general_wrap_validator_functionclient = openai.Client(api_key=openai.api_key)

def encode_image_base64(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

gpt_client = openai.Client(api_key=openai.api_key)

numCorrect = 0
numWrong = 0

# Evaluate a subset of the dataset
df = df.head(200)
print(len(df))
for i in range(len(df)):
    item = df.iloc[i]
    try:
        path1 = os.path.join(IMAGE_FOLDER_TRAIN01, item['image_id'])
        path2 = os.path.join(IMAGE_FOLDER_TRAIN02, item['image_id'])
        if os.path.exists(path1):
          image_path = path1
        elif os.path.exists(path2):
          image_path = path2

        img = Image.open(image_path)

        instructions = "ONLY RESPOND WITH A SINGLE WORD IN ALL CAPS: TRUE or FALSE DO NOT SAY ANYTHING BESIDES THAT SINGLE WORD."

        prompt = f"{instructions}\n{item['question']}"
        image_base64 = encode_image_base64(image_path)
        gpt_response = gpt_client.chat.completions.create(
          model="o4-mini",
          messages=[
              {
                  "role": "user",
                  "content": [
                      {"type": "text", "text": prompt},
                      {
                          "type": "image_url",
                          "image_url": {
                              "url": f"data:image/jpeg;base64,{image_base64}"
                          }
                      }
                  ],
              }
          ],
          max_tokens=50
        )
        gpt_answer = gpt_response.choices[0].message.content

    except Exception as e:
        print(f"An error occurred: {e}")
        continue
    #Turning the gpt answer into a boolean for easy comparison with the ground truth answer
    bool_gpt = gpt_answer.lower() == "true"
    if bool_gpt == item['answer']:
        numCorrect += 1
    else:
        numWrong += 1

#Calculating the final accuracy percentage
accuracy = numCorrect / (numCorrect + numWrong)
print(numCorrect)
print(f"Accuracy: {accuracy * 100}%")
